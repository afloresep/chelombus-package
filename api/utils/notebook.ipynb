{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "input_folder = \"/mnt/samsung_2tb/mixed_data/output/pca_transformed_results/output/\"\n",
    "\n",
    "# df = pd.read_parquet(os.path.join(input_folder, \"output_dataframe_0.parquet\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.DataFrame()\n",
    "\n",
    "for i in range(4):\n",
    "    path = os.path.join(input_folder, f\"output_dataframe_{i}.parquet\")\n",
    "\n",
    "    da= da.append(pd.read_parquet(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PCA_1\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdigest import TDigest\n",
    "import numpy as np\n",
    "\n",
    "digest = TDigest()\n",
    "\n",
    "digest.batch_update(da[\"PCA_1\"].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.62286448783357"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digest.percentile(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "import pickle\n",
    "\n",
    "with open(\"tdigest.pkl\", 'rb') as f:\n",
    "    digest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: [0.10017561 0.25009912 0.49998359 0.74995481 0.89985113]\n"
     ]
    }
   ],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# Create a large Dask array (simulate distributed data)\n",
    "data = da.random.random(size=1_100_000_000, chunks=100_000)  # 1M elements, 10 chunks\n",
    "\n",
    "# Percentiles to compute\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "\n",
    "# Calculate percentiles using TDigest method\n",
    "result = da.percentile(data, q=percentiles, method='linear', internal_method='tdigest')\n",
    "\n",
    "# Compute and print the results\n",
    "print(\"Percentiles:\", result.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th percentile of PCA_1: -22.3494601290862\n",
      "2th percentile of PCA_1: -13.146549090536524\n",
      "4th percentile of PCA_1: -12.151756258227447\n",
      "6th percentile of PCA_1: -11.151671236329406\n",
      "8th percentile of PCA_1: -9.592409584386983\n",
      "10th percentile of PCA_1: -8.254401694966019\n",
      "12th percentile of PCA_1: -7.484747681025569\n",
      "14th percentile of PCA_1: -6.911097772465119\n",
      "16th percentile of PCA_1: -6.437421390527987\n",
      "18th percentile of PCA_1: -6.040093269518786\n",
      "20th percentile of PCA_1: -5.687396672472152\n",
      "22th percentile of PCA_1: -5.357547216571537\n",
      "24th percentile of PCA_1: -5.030769196497266\n",
      "26th percentile of PCA_1: -4.695513839153042\n",
      "28th percentile of PCA_1: -4.35916202040532\n",
      "30th percentile of PCA_1: -4.004679122419613\n",
      "32th percentile of PCA_1: -3.6233083642575696\n",
      "34th percentile of PCA_1: -3.206035997114414\n",
      "36th percentile of PCA_1: -2.751876987810707\n",
      "38th percentile of PCA_1: -2.2742940458320082\n",
      "40th percentile of PCA_1: -1.818145589954938\n",
      "42th percentile of PCA_1: -1.3608777530485376\n",
      "44th percentile of PCA_1: -0.9529676196090131\n",
      "46th percentile of PCA_1: -0.5885951720522461\n",
      "48th percentile of PCA_1: -0.2539804475335017\n",
      "50th percentile of PCA_1: 0.07929446726735727\n",
      "52th percentile of PCA_1: 0.42034767930330447\n",
      "54th percentile of PCA_1: 0.7586092856038645\n",
      "56th percentile of PCA_1: 1.078852129719347\n",
      "58th percentile of PCA_1: 1.374632159124523\n",
      "60th percentile of PCA_1: 1.6792012292726721\n",
      "62th percentile of PCA_1: 1.9937383526674106\n",
      "64th percentile of PCA_1: 2.3291340302877925\n",
      "66th percentile of PCA_1: 2.671615245779528\n",
      "68th percentile of PCA_1: 3.024111841728888\n",
      "70th percentile of PCA_1: 3.392275360144193\n",
      "72th percentile of PCA_1: 3.792793509289029\n",
      "74th percentile of PCA_1: 4.2213655488520265\n",
      "76th percentile of PCA_1: 4.681654014589579\n",
      "78th percentile of PCA_1: 5.189925890596955\n",
      "80th percentile of PCA_1: 5.707442841550563\n",
      "82th percentile of PCA_1: 6.278827805513368\n",
      "84th percentile of PCA_1: 6.834518136462699\n",
      "86th percentile of PCA_1: 7.420256246682369\n",
      "88th percentile of PCA_1: 8.074651632903716\n",
      "90th percentile of PCA_1: 8.756378401848192\n",
      "92th percentile of PCA_1: 9.574635518301982\n",
      "94th percentile of PCA_1: 10.579372492614361\n",
      "96th percentile of PCA_1: 11.992858154020679\n",
      "98th percentile of PCA_1: 14.274279363329555\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "# Define the input path\n",
    "input_folder = \"/mnt/samsung_2tb/mixed_data/output/pca_transformed_results/output/*.parquet\"\n",
    "\n",
    "# Read the Parquet files, selecting only 'PCA_1' column\n",
    "df = dd.read_parquet(input_folder, columns=['PCA_1', 'PCA_2', 'PCA_3'], engine='pyarrow')  # or engine='pyarrow'\n",
    "\n",
    "\n",
    "# Convert 'PCA_1' column to a Dask array\n",
    "pca1_array = df['PCA_1'].to_dask_array(lengths=True)\n",
    "\n",
    "# Define the percentiles to compute\n",
    "percentiles_to_compute = [i for i in np.arange(100, step=2)]\n",
    "\n",
    "# Compute the percentiles using Dask's internal method\n",
    "percentiles = da.percentile(\n",
    "    pca1_array, \n",
    "    q=percentiles_to_compute, \n",
    "    method='linear', \n",
    "    internal_method='tdigest'  # or 'tdigest' for memory efficiency\n",
    ").compute()\n",
    "\n",
    "# Print the results\n",
    "for q, value in zip(percentiles_to_compute, percentiles):\n",
    "    print(f\"{q}th percentile of PCA_1: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"PCA_1\"] < -13.146549090536524]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA_1    134206902\n",
       "PCA_2    134206902\n",
       "PCA_3    134206902\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count().compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
